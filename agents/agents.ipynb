{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac167a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: requests~=2.32.0 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.8.3)\n",
      "Requirement already satisfied: wikipedia in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from wikipedia) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\practice\\langchain-practice\\venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv\n",
    "!pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45273a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper,verbose=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a3d589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025A289837D0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.langchain.com/labs/oap/quickstart\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fcfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94d18be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever, \"langchain_docs\", \"useful for when you need to find information about langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cc69f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "arxiv = ArxivAPIWrapper()\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "608c7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv_tool, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "233c3fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(verbose=True, api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\Practice\\\\langchain-practice\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(),\n",
       " Tool(name='langchain_docs', description='useful for when you need to find information about langchain', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000259C3681120>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025A289837D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000259C36811C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025A289837D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ede537b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\", max_retries=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1026f66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Practice\\langchain-practice\\venv\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0027139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import  create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ea68755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025A2884A780>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025A28849640>, model_name='gpt-4', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_retries=3), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'langchain_docs', 'description': 'useful for when you need to find information about langchain', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(verbose=True, api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\Practice\\\\langchain-practice\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(), Tool(name='langchain_docs', description='useful for when you need to find information about langchain', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000259C3681120>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025A289837D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000259C36811C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000025A289837D0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71ec5f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a software framework designed to facilitate the integration of large language models (LLMs) into applications. It serves as a language model integration framework, providing a streamlined process for incorporating LLMs into various applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is LangChain? Summarize it in a few sentences.',\n",
       " 'output': 'LangChain is a software framework designed to facilitate the integration of large language models (LLMs) into applications. It serves as a language model integration framework, providing a streamlined process for incorporating LLMs into various applications.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is LangChain? Summarize it in a few sentences.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "624fc73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'n8n'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: N8n\n",
      "Summary: n8n (pronounced \"n-eight-n\") is a workflow automation platform developed by n8n GmbH, headquartered in Berlin, Germany. The software provides a visual, node-based editor for buildin\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langchain_docs` with `{'query': 'n8n integration'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m​2. Authentication Setup\n",
      "Open Agent Platform uses Supabase for authentication by default.\n",
      "1Create a Supabase ProjectCreate a new project in Supabase.2Configure Environment VariablesSet the following environment variables inside the apps/web/ directory:You can find these Next.js-specific variables in the “Connect” window in the Supabase dashboard, under “App Frameworks”CopyNEXT_PUBLIC_SUPABASE_URL=\"<your supabase url>\"\n",
      "NEXT_PUBLIC_SUPABASE_ANON_KEY=\"<your supabase anon key>\"\n",
      "3Enable Authentication ProvidersEnable Google authentication in your Supabase project, or set NEXT_PUBLIC_GOOGLE_AUTH_DISABLED=true in your environment variables to disable showing Google as an authentication option in the UI.\n",
      "​3. Deploying Agents\n",
      "The next step in setting up Open Agent Platform is to deploy and configure your agents.\n",
      "1Clone Pre-built AgentsWe’ve released three pre-built agents specifically for Open Agent Platform:\n",
      "Tools Agent\n",
      "Supervisor Agent\n",
      "Deep Research Agent\n",
      "\n",
      "\"isDefault\": \"Whether this deployment is the default deployment (only one can be default)\",\n",
      "  \"defaultGraphId\": \"The graph ID of the default graph (optional, only required if isDefault is true)\"\n",
      "}\n",
      "You can find your project & tenant IDs with a GET request to the /info endpoint on your LangGraph Platform deployment.If you are running agents locally via langgraph dev, the id (project ID), and tenantId should be any valid UUID version 4, such as those generated by uuid.uuid4(). Ensure each graph has a unique id, and all graphs share the same tenantId.4Set Environment VariablesCombine your agent configurations into a JSON array and set the NEXT_PUBLIC_DEPLOYMENTS environment variable inside the apps/web/ directory:CopyNEXT_PUBLIC_DEPLOYMENTS=[{\"id\":\"bf63dc89-1de7-4a65-8336-af9ecda479d6\",\"deploymentUrl\":\"http://localhost:2024\",\"tenantId\":\"42d732b3-1324-4226-9fe9-513044dceb58\",\"name\":\"Local deployment\",\"isDefault\":true,\"defaultGraphId\":\"agent\"}]\n",
      "\n",
      "Quick Start - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLabsExperimental AI products from LangChainGet StartedIntroductionQuick StartSetupAgents SetupAuthentication SetupRAG Server SetupMCP ServerCustom agentsCustom Agents OverviewAgent ConfigurationOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationGet StartedQuick StartOverviewDeep AgentsOpen SWEOpen Agent PlatformOverviewDeep AgentsOpen SWEOpen Agent PlatformGitHubTry LangSmithOn this page1. Download the Open Agent Platform code2. Authentication Setup3. Deploying Agents4. RAG Server Setup5. MCP Server Setup6. Run Your PlatformGet StartedQuick StartCopy pageFollow these steps to get your Open Agent Platform up and running quickly.Copy pagePrerequisites:\n",
      "\n",
      "​6. Run Your Platform\n",
      "Start the application with your configured environment variables:\n",
      "Copy# Navigate to the web app directory\n",
      "cd apps/web\n",
      "\n",
      "# Install dependencies\n",
      "yarn install\n",
      "\n",
      "# Start the development server\n",
      "yarn dev\n",
      "\n",
      "Your Open Agent Platform should now be running at http://localhost:3000!Was this page helpful?YesNoIntroductionAgents Setup⌘IAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mn8n (pronounced \"n-eight-n\") is a workflow automation platform developed by n8n GmbH, headquartered in Berlin, Germany. The software provides a visual, node-based editor for building workflows.\n",
      "\n",
      "As for its integration with LangChain, the documentation does not provide specific details on how n8n can be used with LangChain. However, given that n8n is a workflow automation tool, it could potentially be used to automate various tasks and processes within LangChain, such as data processing, task scheduling, and more.\n",
      "\n",
      "For example, you could set up a workflow in n8n to automatically process and analyze new data as it comes into LangChain, or to schedule regular updates and maintenance tasks. This could help to streamline your work with LangChain and make your processes more efficient.\n",
      "\n",
      "Please note that this is a general suggestion and the actual integration process would depend on the specific requirements and capabilities of both LangChain and n8n.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is n8n and how can it be used with LangChain?',\n",
       " 'output': 'n8n (pronounced \"n-eight-n\") is a workflow automation platform developed by n8n GmbH, headquartered in Berlin, Germany. The software provides a visual, node-based editor for building workflows.\\n\\nAs for its integration with LangChain, the documentation does not provide specific details on how n8n can be used with LangChain. However, given that n8n is a workflow automation tool, it could potentially be used to automate various tasks and processes within LangChain, such as data processing, task scheduling, and more.\\n\\nFor example, you could set up a workflow in n8n to automatically process and analyze new data as it comes into LangChain, or to schedule regular updates and maintenance tasks. This could help to streamline your work with LangChain and make your processes more efficient.\\n\\nPlease note that this is a general suggestion and the actual integration process would depend on the specific requirements and capabilities of both LangChain and n8n.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is n8n and how can it be used with LangChain?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
